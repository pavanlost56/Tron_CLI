# CodeInsight Configuration Example

# Application Settings
DEBUG=false

# LLM Provider Settings
LLM_PROVIDER=ollama  # Options: ollama, mistral
LLM_MODEL=codellama:13b

# Ollama Settings
OLLAMA_HOST=http://localhost:11434

# Mistral AI Settings (Required if using Mistral)
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_EMBEDDING_MODEL=mistral-embed
MISTRAL_CHAT_MODEL=mistral-small
USE_MISTRAL_EMBEDDINGS=false  # Set to true to use Mistral for embeddings

# Vector Database Settings
EMBEDDING_MODEL=all-MiniLM-L6-v2  # Local embedding model (used if USE_MISTRAL_EMBEDDINGS=false)

# API Settings
API_HOST=0.0.0.0
API_PORT=8000

# MCP Settings
MCP_TIMEOUT=30
MAX_RETRIES=3
